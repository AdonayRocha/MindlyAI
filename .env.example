# Exemplo de configuração para MindlyAI
# Renomeie para .env e preencha com seus dados reais

# Chave de API do Groq (obrigatório para geração de texto)
GROQ_API_KEY=

# Chaves de acesso à API (separadas por vírgula, ex: admin,usuario2)
API_KEYS=admin

# Modo do gerador: "hf" para Hugging Face, "local" para Ollama (atualmente só Groq está ativo)
GEN_MODEL_MODE=hf

# Nome/slug do modelo a usar (ex: mistral, llama3, etc.)
GEN_MODEL_NAME=mistral

# Modelo para detecção de emoções (apenas se usar Hugging Face)
EMOTION_MODEL=valhalla/distilbart-mnli-12-1

# Parâmetros de geração
GEN_TEMPERATURE=0.6
GEN_MAX_TOKENS=200

# Configuração do Ollama (ignore se não usar)
OLLAMA_HOST=ollama
OLLAMA_PORT=11434

# Configuração local / deploy
ENV=development
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info

# (Opcional) Token do Hugging Face (se usar HF)
MINDLY_TOKEN=
